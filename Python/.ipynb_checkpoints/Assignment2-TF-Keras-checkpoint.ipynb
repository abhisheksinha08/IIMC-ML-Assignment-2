{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly.tools as tls\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('Data Set for Assignment II - 1000 Records 75 Attributes.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record Serial Number</th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>...</th>\n",
       "      <th>AWALAND</th>\n",
       "      <th>APERSAUT</th>\n",
       "      <th>ABESAUT</th>\n",
       "      <th>AMOTSCO</th>\n",
       "      <th>AVRAAUT</th>\n",
       "      <th>AAANHANG</th>\n",
       "      <th>ATRACTOR</th>\n",
       "      <th>AWERKT</th>\n",
       "      <th>ABROM</th>\n",
       "      <th>OUTCOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Record Serial Number  MOSTYPE   MAANTHUI   MGEMOMV   MGEMLEEF   MOSHOOFD   \\\n",
       "0                     1         9          1         3          3          3   \n",
       "1                     2        33          1         4          3          8   \n",
       "2                     3         8          2         3          3          2   \n",
       "3                     4        39          1         3          3          9   \n",
       "4                     5        33          1         3          3          8   \n",
       "\n",
       "   MGODRK   MGODPR   MGODOV   MGODGE    ...     AWALAND   APERSAUT   ABESAUT   \\\n",
       "0        1        4        1        5   ...            0          1         0   \n",
       "1        0        6        0        3   ...            0          0         0   \n",
       "2        2        4        1        3   ...            0          0         0   \n",
       "3        1        4        1        5   ...            0          1         0   \n",
       "4        0        5        0        4   ...            0          0         0   \n",
       "\n",
       "   AMOTSCO   AVRAAUT   AAANHANG   ATRACTOR   AWERKT   ABROM   OUTCOME  \n",
       "0         0         0          0          0        0       0        0  \n",
       "1         0         0          0          0        0       0        0  \n",
       "2         0         0          0          0        0       0        0  \n",
       "3         0         0          0          0        0       0        0  \n",
       "4         0         0          0          0        0       0        0  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop Record Serial Number\n",
    "data.drop('Record Serial Number', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MOSTYPE ', 'MAANTHUI ', 'MGEMOMV ', 'MGEMLEEF ', 'MOSHOOFD ',\n",
       "       'MGODRK ', 'MGODPR ', 'MGODOV ', 'MGODGE ', 'MRELGE ', 'MRELSA ',\n",
       "       'MRELOV ', 'MFALLEEN ', 'MFGEKIND ', 'MFWEKIND ', 'MOPLHOOG ',\n",
       "       'MOPLMIDD ', 'MOPLLAAG ', 'MBERHOOG ', 'MBERZELF ', 'MBERBOER ',\n",
       "       'MBERMIDD ', 'MBERARBG ', 'MBERARBO ', 'MSKA ', 'MSKB1 ', 'MSKB2 ',\n",
       "       'MSKC ', 'MSKD ', 'MHHUUR ', 'MHKOOP ', 'MAUT1 ', 'MAUT2 ', 'MAUT0 ',\n",
       "       'MZFONDS ', 'MZPART ', 'MINKM30 ', 'MINK3045 ', 'MINK4575 ',\n",
       "       'MINK7512 ', 'MINK123M ', 'MINKGEM ', 'MKOOPKLA ', 'PWAPART ',\n",
       "       'PWABEDR ', 'PWALAND ', 'PPERSAUT ', 'PBESAUT ', 'PMOTSCO ', 'PVRAAUT ',\n",
       "       'PAANHANG ', 'PTRACTOR ', 'PWERKT ', 'PBROM ', 'PLEVEN ', 'PPERSONG ',\n",
       "       'PGEZONG ', 'PWAOREG ', 'PBRAND ', 'PZEILPL ', 'PPLEZIER ', 'PFIETS ',\n",
       "       'PINBOED ', 'PBYSTAND ', 'AWAPART ', 'AWABEDR ', 'AWALAND ',\n",
       "       'APERSAUT ', 'ABESAUT ', 'AMOTSCO ', 'AVRAAUT ', 'AAANHANG ',\n",
       "       'ATRACTOR ', 'AWERKT ', 'ABROM ', 'OUTCOME'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 76) (1000,)\n"
     ]
    }
   ],
   "source": [
    "X_all = data.iloc[:,0:76]\n",
    "y_all = data['OUTCOME']\n",
    "print(X_all.shape, y_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Fields with Zero or 5% Variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vt = VarianceThreshold(threshold=0.05)\n",
    "vt_data = vt.fit(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing near-zero variance fields: (1000, 60)\n"
     ]
    }
   ],
   "source": [
    "X_all = X_all.iloc[:,vt_data.get_support()]\n",
    "print(\"Shape after removing near-zero variance fields:\", X_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_std:  (1000, 60)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_all)\n",
    "print(\"Shape of X_std: \", X_std.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tls.set_credentials_file(username='abhishek.sparta', api_key='yudmTNxLLBWQrw3yNaQX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eig_vals = pca.explained_variance_ratio_\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "trace1 = Bar(\n",
    "        x=['PC %s' %i for i in range(1,50)],\n",
    "        y=var_exp,\n",
    "        showlegend=False)\n",
    "\n",
    "trace2 = Scatter(\n",
    "        x=['PC %s' %i for i in range(1,50)], \n",
    "        y=cum_var_exp,\n",
    "        name='cumulative explained variance')\n",
    "\n",
    "data = Data([trace1, trace2])\n",
    "\n",
    "layout=Layout(\n",
    "        yaxis=YAxis(title='Explained variance in percent'),\n",
    "        title='Explained variance by different principal components')\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "#py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting First 37 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_pca:  (1000, 37)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=37)\n",
    "X_pca = pca.fit_transform(X_std)\n",
    "print(\"Shape of X_pca: \", X_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_pca = scaler.fit_transform(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Split - Train, Valid and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = pd.DataFrame(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (650, 37) , X_test:  (350, 37) , y_train:  (650,) , y_test:  (350,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.35, random_state=123)\n",
    "print(\"X_train:\", X_train.shape, \", X_test: \", X_test.shape, \", y_train: \", y_train.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid: (200, 37) , X_test:  (150, 37) , y_valid:  (200,) , y_test:  (150,)\n"
     ]
    }
   ],
   "source": [
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.427, random_state=123)\n",
    "print(\"X_valid:\", X_valid.shape, \", X_test: \", X_test.shape, \", y_valid: \", y_valid.shape, \", y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(tn, fn, tp, fp):\n",
    "    return( (fn * -1000) + (tp*9000) + (fp * -9000) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    y_pred = K.round(y_pred)\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(activation=\"relu\", units=100, input_dim=37))\n",
    "model.add(Dense(activation=\"sigmoid\", units=1))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "650/650 [==============================] - 0s - loss: 0.3445 - acc: 0.9354 - f1: nan     \n",
      "Epoch 2/50\n",
      "650/650 [==============================] - 0s - loss: 0.2407 - acc: 0.9354 - f1: nan     \n",
      "Epoch 3/50\n",
      "650/650 [==============================] - 0s - loss: 0.2360 - acc: 0.9354 - f1: nan     \n",
      "Epoch 4/50\n",
      "650/650 [==============================] - 0s - loss: 0.2306 - acc: 0.9354 - f1: nan     \n",
      "Epoch 5/50\n",
      "650/650 [==============================] - 0s - loss: 0.2256 - acc: 0.9354 - f1: nan     \n",
      "Epoch 6/50\n",
      "650/650 [==============================] - 0s - loss: 0.2198 - acc: 0.9354 - f1: nan     \n",
      "Epoch 7/50\n",
      "650/650 [==============================] - 0s - loss: 0.2143 - acc: 0.9354 - f1: nan     \n",
      "Epoch 8/50\n",
      "650/650 [==============================] - 0s - loss: 0.2066 - acc: 0.9354 - f1: nan     \n",
      "Epoch 9/50\n",
      "650/650 [==============================] - 0s - loss: 0.1995 - acc: 0.9354 - f1: nan     \n",
      "Epoch 10/50\n",
      "650/650 [==============================] - 0s - loss: 0.1923 - acc: 0.9354 - f1: nan     \n",
      "Epoch 11/50\n",
      "650/650 [==============================] - 0s - loss: 0.1841 - acc: 0.9354 - f1: nan     \n",
      "Epoch 12/50\n",
      "650/650 [==============================] - 0s - loss: 0.1733 - acc: 0.9354 - f1: nan     \n",
      "Epoch 13/50\n",
      "650/650 [==============================] - 0s - loss: 0.1614 - acc: 0.9354 - f1: nan     \n",
      "Epoch 14/50\n",
      "650/650 [==============================] - 0s - loss: 0.1529 - acc: 0.9354 - f1: nan     \n",
      "Epoch 15/50\n",
      "650/650 [==============================] - 0s - loss: 0.1456 - acc: 0.9354 - f1: nan     \n",
      "Epoch 16/50\n",
      "650/650 [==============================] - 0s - loss: 0.1291 - acc: 0.9354 - f1: nan     \n",
      "Epoch 17/50\n",
      "650/650 [==============================] - 0s - loss: 0.1175 - acc: 0.9354 - f1: nan     \n",
      "Epoch 18/50\n",
      "650/650 [==============================] - 0s - loss: 0.1060 - acc: 0.9354 - f1: nan     \n",
      "Epoch 19/50\n",
      "650/650 [==============================] - 0s - loss: 0.0944 - acc: 0.9508 - f1: nan     \n",
      "Epoch 20/50\n",
      "650/650 [==============================] - 0s - loss: 0.0849 - acc: 0.9631 - f1: nan     \n",
      "Epoch 21/50\n",
      "650/650 [==============================] - 0s - loss: 0.0763 - acc: 0.9892 - f1: nan        \n",
      "Epoch 22/50\n",
      "650/650 [==============================] - 0s - loss: 0.0670 - acc: 0.9769 - f1: nan     \n",
      "Epoch 23/50\n",
      "650/650 [==============================] - 0s - loss: 0.0587 - acc: 0.9938 - f1: nan        \n",
      "Epoch 24/50\n",
      "650/650 [==============================] - 0s - loss: 0.0520 - acc: 0.9954 - f1: nan       \n",
      "Epoch 25/50\n",
      "650/650 [==============================] - 0s - loss: 0.0469 - acc: 0.9985 - f1: nan       \n",
      "Epoch 26/50\n",
      "650/650 [==============================] - 0s - loss: 0.0450 - acc: 0.9892 - f1: nan     \n",
      "Epoch 27/50\n",
      "650/650 [==============================] - 0s - loss: 0.0368 - acc: 0.9985 - f1: nan       \n",
      "Epoch 28/50\n",
      "650/650 [==============================] - 0s - loss: 0.0346 - acc: 0.9985 - f1: nan       \n",
      "Epoch 29/50\n",
      "650/650 [==============================] - 0s - loss: 0.0305 - acc: 0.9985 - f1: nan     \n",
      "Epoch 30/50\n",
      "650/650 [==============================] - 0s - loss: 0.0280 - acc: 0.9985 - f1: nan     \n",
      "Epoch 31/50\n",
      "650/650 [==============================] - 0s - loss: 0.0247 - acc: 0.9985 - f1: nan       \n",
      "Epoch 32/50\n",
      "650/650 [==============================] - 0s - loss: 0.0225 - acc: 0.9985 - f1: nan       \n",
      "Epoch 33/50\n",
      "650/650 [==============================] - 0s - loss: 0.0208 - acc: 0.9985 - f1: nan       \n",
      "Epoch 34/50\n",
      "650/650 [==============================] - 0s - loss: 0.0187 - acc: 0.9985 - f1: nan       \n",
      "Epoch 35/50\n",
      "650/650 [==============================] - 0s - loss: 0.0171 - acc: 1.0000 - f1: nan       \n",
      "Epoch 36/50\n",
      "650/650 [==============================] - 0s - loss: 0.0157 - acc: 1.0000 - f1: nan       \n",
      "Epoch 37/50\n",
      "650/650 [==============================] - 0s - loss: 0.0145 - acc: 1.0000 - f1: nan       \n",
      "Epoch 38/50\n",
      "650/650 [==============================] - 0s - loss: 0.0135 - acc: 1.0000 - f1: nan       \n",
      "Epoch 39/50\n",
      "650/650 [==============================] - 0s - loss: 0.0126 - acc: 1.0000 - f1: nan       \n",
      "Epoch 40/50\n",
      "650/650 [==============================] - 0s - loss: 0.0116 - acc: 1.0000 - f1: nan       \n",
      "Epoch 41/50\n",
      "650/650 [==============================] - 0s - loss: 0.0107 - acc: 1.0000 - f1: nan       \n",
      "Epoch 42/50\n",
      "650/650 [==============================] - 0s - loss: 0.0104 - acc: 1.0000 - f1: nan       \n",
      "Epoch 43/50\n",
      "650/650 [==============================] - 0s - loss: 0.0095 - acc: 1.0000 - f1: nan       \n",
      "Epoch 44/50\n",
      "650/650 [==============================] - 0s - loss: 0.0088 - acc: 1.0000 - f1: nan       \n",
      "Epoch 45/50\n",
      "650/650 [==============================] - 0s - loss: 0.0083 - acc: 1.0000 - f1: nan        \n",
      "Epoch 46/50\n",
      "650/650 [==============================] - 0s - loss: 0.0078 - acc: 1.0000 - f1: nan        \n",
      "Epoch 47/50\n",
      "650/650 [==============================] - 0s - loss: 0.0074 - acc: 1.0000 - f1: nan       \n",
      "Epoch 48/50\n",
      "650/650 [==============================] - 0s - loss: 0.0069 - acc: 1.0000 - f1: nan       \n",
      "Epoch 49/50\n",
      "650/650 [==============================] - 0s - loss: 0.0066 - acc: 1.0000 - f1: nan       \n",
      "Epoch 50/50\n",
      "650/650 [==============================] - 0s - loss: 0.0063 - acc: 1.0000 - f1: nan       \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a419780>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X_train), np.array(y_train), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/650 [>.............................] - ETA: 0s\n",
      "acc: 100.00%\n",
      "\n",
      "f1: nan\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "scores = model.evaluate(np.array(X_train), np.array(y_train))\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(\"\\n%s: %.2f\" % (model.metrics_names[2], scores[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[193   0]\n",
      " [  0   7]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(np.array(X_valid))\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "con_matrix = confusion_matrix(y_valid, rounded)\n",
    "\n",
    "print(con_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of Validation Set:  63000\n"
     ]
    }
   ],
   "source": [
    "cost_val = cost(con_matrix[0][0], con_matrix[0][1], con_matrix[1][1], con_matrix[1][0])\n",
    "print(\"Cost of Validation Set: \", cost_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[142   0]\n",
      " [  0   8]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(np.array(X_test))\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "con_matrix = confusion_matrix(y_test, rounded)\n",
    "\n",
    "print(con_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of Test Set:  72000\n"
     ]
    }
   ],
   "source": [
    "cost_test = cost(con_matrix[0][0], con_matrix[0][1], con_matrix[1][1], con_matrix[1][0])\n",
    "print(\"Cost of Test Set: \", cost_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
